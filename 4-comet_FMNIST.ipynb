{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "comet_FMNIST.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "mimetype": "text/x-python",
      "pygments_lexer": "ipython3",
      "name": "python",
      "file_extension": ".py",
      "version": "3.5.2",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      },
      "nbconvert_exporter": "python"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "n6d98zVNZeO6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install comet_ml"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k2Ze4ExpdDr4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from comet_ml import Experiment"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Idrj-_DU2nfT",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import torch\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(torch.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QjrsEoVl6gm5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Fashion MINST dataset\n"
      ]
    },
    {
      "metadata": {
        "id": "6usBsSGi6k6u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import FashionMNIST"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r49OsLdH6yRo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Getting the train and test parts of the dataset\n",
        "data_train = FashionMNIST(\"FashionMNIST/\",\n",
        "                          download=True,\n",
        "                          train=True)\n",
        "\n",
        "data_test = FashionMNIST(\"FashionMNIST/\",\n",
        "                          download=True,\n",
        "                          train=False)\n",
        "\n",
        "# In fact, it's already stored as torch tensor, but we'll need\n",
        "# to work with the numpy representation, so let's do the convertion:\n",
        "X_train = data_train.train_data.numpy()\n",
        "y_train = data_train.train_labels.numpy()\n",
        "\n",
        "X_test = data_test.test_data.numpy()\n",
        "y_test = data_test.test_labels.numpy()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p-VvVjxj8IEk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The datasets consists of images belonging to one out of 10 classes:\n",
        "\n",
        "| Label | Description | | Label | Description |\n",
        "| ---       \n",
        "| 0        | T-shirt/top   || 5        | Sandal         |\n",
        "| 1        | Trouser        || 6        | Shirt             |\n",
        "| 2        | Pullover       || 7        | Sneaker       |\n",
        "| 3        | Dress           || 8        | Bag              |\n",
        "| 4        | Coat             || 9        | Ankle boot  |\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "gSPYLKzJAgzO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Input preprocessing"
      ]
    },
    {
      "metadata": {
        "id": "Vl-0UxIJxTkn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "So far our data is held as numpy arrays of unsigned byte type, i.e. it lies within a range from 0 to 255. Also, the shape of our input is 3-dimensional (num_images, height, width), while our `model` takes 2-dimensional \"arrays of 1-dimensional images\" (num_images, height * width)."
      ]
    },
    {
      "metadata": {
        "id": "XF2nptPHx3-g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We have to convert that to `torch` tensors and reshape the input. Also, it's a good idea to normalize your image data to lie within a $[0, 1]$ interval. Let's write a function that does all these things:"
      ]
    },
    {
      "metadata": {
        "id": "TMiuBEH42Hso",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Write a function to convert X and y to torch tensors while\n",
        "# rescaling X to fit into [0, 1] interval and reshaping it properly\n",
        "\n",
        "# Hint: make sure your input tensor dtype is same as the\n",
        "# parameters of the model (should be torch.float)\n",
        "\n",
        "def preprocess_data(X, y):\n",
        "  X_preprocessed = torch.reshape(torch.from_numpy(X/ 255.).type(torch.float32), (-1, 784))\n",
        "  y_preprocessed = torch.from_numpy(y)\n",
        "  return X_preprocessed, y_preprocessed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NL1rGhZUxshQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Some utilities"
      ]
    },
    {
      "metadata": {
        "id": "FKlNWpZ5kOQX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Batch generator\n",
        "# (here's a very brief description of what python generators are:\n",
        "# https://stackoverflow.com/a/231855/3801744)\n",
        "def get_batches(X, y, batch_size, shuffle=False):\n",
        "  if shuffle:\n",
        "    shuffle_ids = np.random.permutation(len(X))\n",
        "    X = X[shuffle_ids].copy()\n",
        "    y = y[shuffle_ids].copy()\n",
        "  for i_picture in range(0, len(X), batch_size):\n",
        "    # Get batch and preprocess it:\n",
        "    batch_X = X[i_picture:i_picture + batch_size]\n",
        "    batch_y = y[i_picture:i_picture + batch_size]\n",
        "    \n",
        "    # 'return' the batch (see the link above to\n",
        "    # better understand what 'yield' does)\n",
        "    yield preprocess_data(batch_X, batch_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qSEGq892e9qZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_test_predictions(model, batch_size=100):\n",
        "  predictions_test = np.concatenate([\n",
        "    model(batch_X).to('cpu').detach().numpy()\n",
        "    for batch_X, batch_y in get_batches(X_test, y_test, batch_size)\n",
        "  ], axis=0)\n",
        "  return np.argmax(predictions_test, axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MFDC8dtcT64T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Main training loop\n"
      ]
    },
    {
      "metadata": {
        "id": "4U3YMWEUvL6T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train2score(n_epochs, batch_size=100, learning_rate=0.001, hidden_size=100):\n",
        "  global experiment\n",
        "  experiment.log_parameters({\n",
        "      'n_epochs': n_epochs,\n",
        "      'batch_size': batch_size,\n",
        "      'learning_rate': learning_rate,\n",
        "      'hidden_size': hidden_size})\n",
        "  # Defining the loss function:\n",
        "  loss_function = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "  # Defining the model\n",
        "  input_size = 28 * 28 # number of pixels per image\n",
        "  output_size = 10 # number of classes\n",
        "\n",
        "  model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(input_size, hidden_size),\n",
        "    torch.nn.ELU(),\n",
        "    torch.nn.Linear(hidden_size, output_size),\n",
        "  )\n",
        "\n",
        "  # Setting up the optimizer\n",
        "  learning_rate = 0.005\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "  for i_epoch in range(n_epochs):\n",
        "    for batch_X, batch_y in get_batches(X_train, y_train,\n",
        "                                        batch_size=batch_size,\n",
        "                                        shuffle=True):\n",
        "\n",
        "      # Compute the loss, zero the gradients, and make an optimization step\n",
        "      predictions = model(batch_X) # compute the predictions\n",
        "      loss = loss_function(predictions, batch_y) # compute the loss\n",
        "\n",
        "      model.zero_grad() # zero the gradients\n",
        "      loss.backward() # compute new gradients\n",
        "      optimizer.step() # do an optimization step\n",
        "\n",
        "    for batch_X, batch_y in get_batches(X_test, y_test,\n",
        "                                        batch_size=batch_size):\n",
        "\n",
        "      # Compute the loss\n",
        "      predictions = model(batch_X) # compute the predictions\n",
        "      loss = loss_function(predictions, batch_y) # compute the loss\n",
        "    accuracy = accuracy_score(get_test_predictions(model), y_test)\n",
        "    experiment.log_metrics({'accuracy': accuracy, 'loss': loss.item()})\n",
        "\n",
        "  experiment.end()\n",
        "  return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qv6R9kqbl5Of",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_epochs = 5\n",
        "learning_rate = 0.0005\n",
        "hidden_size = 100\n",
        "experiment = Experiment(api_key=<YOUR KEY>, project_name=\"comet demo\")\n",
        "score = train2score(n_epochs=n_epochs, learning_rate=learning_rate, \n",
        "                    hidden_size=hidden_size)\n",
        "print (\"Score: {}\".format(score))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TLXkTwY06VoJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Homework\n",
        "\n",
        "1. Add more convolutional magic\n",
        "\n",
        "```\n",
        "model = torch.nn.Sequential(\n",
        "            Reshape(-1, 1, 28, 28),\n",
        "            torch.nn.Conv2d(in_channels=1,\n",
        "                            out_channels=8,\n",
        "                            kernel_size=3,\n",
        "                            padding=1),\n",
        "            torch.nn.Dropout(p=dropout_rate),\n",
        "            torch.nn.ELU(),\n",
        "            torch.nn.MaxPool2d(2),\n",
        "            torch.nn.Conv2d(in_channels=8,\n",
        "                            out_channels=16,\n",
        "                            kernel_size=3,\n",
        "                            padding=1),\n",
        "            torch.nn.Dropout(p=dropout_rate),\n",
        "            torch.nn.ELU(),\n",
        "            torch.nn.MaxPool2d(2),\n",
        "            torch.nn.Conv2d(in_channels=16,\n",
        "                            out_channels=32,\n",
        "                            kernel_size=3,\n",
        "                            padding=1),\n",
        "            torch.nn.Dropout(p=dropout_rate),\n",
        "            torch.nn.ELU(),\n",
        "            torch.nn.MaxPool2d(2, padding=1),\n",
        "            Reshape(-1, 512),\n",
        "            torch.nn.Linear(512, 10)\n",
        "        ).to(device)\n",
        "```\n",
        "\n",
        "2. Optimise it via scikit-optimize package"
      ]
    },
    {
      "metadata": {
        "id": "GgaHVmsmXHwG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}