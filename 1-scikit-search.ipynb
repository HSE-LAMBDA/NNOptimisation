{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Scikit-learn model optimisation\n",
        "\n## Start from good old GridSearch"
      ],
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# by Andrey Ustyuzhanin with heavy scikit-learn documentation re-use\n",
        "# Kudos go to: Raghav RV <rvraghav93@gmail.com>\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.datasets import make_hastie_10_2\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = make_hastie_10_2(n_samples=8000, random_state=42)\n",
        "print (<YOUR CODE>) #print shape of X, y"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid ={'min_samples_split': <YOUR CODE>} # Range from 2 to 402 with step 10"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The scorers can be either be one of the predefined metric strings or a scorer\n",
        "# callable, like the one returned by make_scorer\n",
        "scoring = {'AUC': 'roc_auc', \n",
        "           'Accuracy': make_scorer(accuracy_score)}\n",
        "\n",
        "# Setting refit='AUC', refits an estimator on the whole dataset with the\n",
        "# parameter setting that has the best cross-validated AUC score.\n",
        "# That estimator is made available at ``gs.best_estimator_`` along with\n",
        "# parameters like ``gs.best_score_``, ``gs.best_parameters_`` and\n",
        "# ``gs.best_index_``\n",
        "gs = GridSearchCV(DecisionTreeClassifier(random_state=42),\n",
        "                  param_grid=param_grid,\n",
        "                  scoring=scoring, cv=5, refit='AUC',\n",
        "                  return_train_score=True)\n",
        "gs.fit(X, y)\n",
        "results = gs.cv_results_"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(13, 13))\n",
        "\n",
        "plt.title(\"GridSearchCV evaluating using multiple scorers simultaneously\",\n",
        "          fontsize=16)\n",
        "\n",
        "plt.xlabel(\"min_samples_split\")\n",
        "plt.ylabel(\"Score\")\n",
        "\n",
        "ax = plt.axes()\n",
        "ax.set_xlim(0, 402)\n",
        "ax.set_ylim(0.73, 1)\n",
        "\n",
        "# Get the regular numpy array from the MaskedArray\n",
        "X_axis = np.array(results['param_min_samples_split'].data, dtype=float)\n",
        "\n",
        "for scorer, color in zip(sorted(scoring), ['g', 'k']):\n",
        "    for sample, style in (('train', '--'), ('test', '-')):\n",
        "        sample_score_mean = results['mean_%s_%s' % (sample, scorer)]\n",
        "        sample_score_std = results['std_%s_%s' % (sample, scorer)]\n",
        "        ax.fill_between(X_axis, sample_score_mean - sample_score_std,\n",
        "                        sample_score_mean + sample_score_std,\n",
        "                        alpha=0.1 if sample == 'test' else 0, color=color)\n",
        "        ax.plot(X_axis, sample_score_mean, style, color=color,\n",
        "                alpha=1 if sample == 'test' else 0.7,\n",
        "                label=\"%s (%s)\" % (scorer, sample))\n",
        "\n",
        "    best_index = np.nonzero(results['rank_test_%s' % scorer] == 1)[0][0]\n",
        "    best_score = results['mean_test_%s' % scorer][best_index]\n",
        "\n",
        "    # Plot a dotted vertical line at the best score for that scorer marked by x\n",
        "    ax.plot([X_axis[best_index], ] * 2, [0, best_score],\n",
        "            linestyle='-.', color=color, marker='x', markeredgewidth=3, ms=8)\n",
        "\n",
        "    # Annotate the best score for that scorer\n",
        "    ax.annotate(\"%0.2f\" % best_score,\n",
        "                (X_axis[best_index], best_score + 0.005))\n",
        "\n",
        "plt.legend(loc=\"best\")\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RandomizedSearch"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import randint as sp_randint\n",
        "from time import time\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# get some data\n",
        "digits = load_digits()\n",
        "X, y = digits.data, digits.target\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(<YOUR CODE>) # X, y shape\n",
        "\nplt.imshow(X[0].reshape(8,8)); "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Utility function to report best scores\n",
        "def report(results, n_top=3):\n",
        "    for i in range(1, n_top + 1):\n",
        "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
        "        for candidate in candidates:\n",
        "            print(\"Model with rank: {0}\".format(i))\n",
        "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
        "                  results['mean_test_score'][candidate],\n",
        "                  results['std_test_score'][candidate]))\n",
        "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
        "            print(\"\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# build a classifier\n",
        "clf = RandomForestClassifier(n_estimators=20)\n",
        "\n",
        "# specify parameters and distributions to sample from\n",
        "param_dist = {\"max_depth\": [3, None],\n",
        "              \"max_features\": sp_randint(1, 11),\n",
        "              \"min_samples_split\": sp_randint(2, 11),\n",
        "              \"min_samples_leaf\": sp_randint(1, 11),\n",
        "              \"bootstrap\": [True, False],\n",
        "              \"criterion\": [\"gini\", \"entropy\"]}"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# run randomized search\n",
        "n_iter_search = 20\n",
        "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
        "                                   n_iter=n_iter_search)\n",
        "\n",
        "start = time()\n",
        "random_search.fit(X, y)\n",
        "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
        "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
        "report(random_search.cv_results_)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compare with GridSearch"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print(clf)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# use a full grid over all parameters\n",
        "param_grid = {\"max_depth\": <YOUR CODE>, # 3 or None\n",
        "              \"max_features\": <YOUR CODE>, # logarithmic from 1 to 10\n",
        "              \"min_samples_split\": [2, 3, 10], #\n",
        "              \"min_samples_leaf\": [1, 3, 10],\n",
        "              \"bootstrap\": <YOUR CODE>, # either True or False\n",
        "              \"criterion\": [\"gini\", \"entropy\"]}\n",
        "\n",
        "# run grid search\n",
        "grid_search = GridSearchCV(clf, param_grid=param_grid)\n",
        "start = time()\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
        "      % (time() - start, len(grid_search.cv_results_['params'])))\n",
        "report(grid_search.cv_results_)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "language_info": {
      "nbconvert_exporter": "python",
      "mimetype": "text/x-python",
      "file_extension": ".py",
      "version": "3.5.2",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      },
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "nteract": {
      "version": "0.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}